{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pandas import DataFrame as df\n",
    "import numpy as np\n",
    "import csv\n",
    "from itertools import combinations\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import stats\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import mutual_info_regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(qual_vec_type = \"500\"):\n",
    "    otu = pd.read_csv(\"data/silva/freshwater/otu_filtered_freshwater.csv\", sep = \"\\t\", index_col=0)\n",
    "    print(otu.shape)\n",
    "    otu.head()\n",
    "    #Delete samples that have no taxa\n",
    "    otu = otu.loc[:, otu.sum(axis=0) != 0]\n",
    "    \n",
    "    #Read quality vector data\n",
    "    if qual_vec_type == \"100\":\n",
    "        qual_vecs = pd.read_csv(\"embeddings/silva/glove_emb_freshwater_100.txt\", sep = \" \", index_col = 0, header=None)\n",
    "    if qual_vec_type == \"500\":\n",
    "        qual_vecs = pd.read_csv(\"embeddings/silva/glove_emb_freshwater_2perc_500.txt\", sep = \" \", index_col = 0, header=None)\n",
    "    print(qual_vecs.shape)\n",
    "    qual_vecs.head()\n",
    "    \n",
    "    #Match taxa present in quality vectors with those in otu table\n",
    "    bools_drop = [i not in qual_vecs.index.values for i in otu.index.values]\n",
    "    drop = otu.index.values[bools_drop]\n",
    "    otu_drop = otu.drop(drop, axis = 0)\n",
    "    print(\"OTU DROP SHAPE: \" + str(otu_drop.shape))\n",
    "    \n",
    "    qual_vecs = qual_vecs.drop(\"<unk>\", axis = 0)\n",
    "    qual_vecs_sort = qual_vecs.reindex(sorted(qual_vecs.index.values), axis = 0)\n",
    "    otu = otu_drop.reindex(sorted(otu_drop.index.values), axis = 0) #Organize otu rows to match taxa in qual_vecs\n",
    "\n",
    "    ntaxa = qual_vecs.shape[0]\n",
    "    print(ntaxa)\n",
    "    bools_correct = [qual_vecs_sort.index.values[i] == otu.index.values[i] for i in range(ntaxa)]\n",
    "\n",
    "    if (np.sum(bools_correct) == qual_vecs_sort.shape[0]) and (np.sum(bools_correct) == otu.shape[0]):\n",
    "        print(\"Safe to continue\")\n",
    "    else:\n",
    "        print(\"STOP! Something is wrong.\")\n",
    "        \n",
    "        \n",
    "    #Read mapping data\n",
    "    mapping = pd.read_csv(\"data/emp_qiime_mapping_release1.tsv.csv\", sep = \",\", index_col=0, encoding='latin1')\n",
    "    print(\"Mapping has shape: \" + str(mapping.shape))\n",
    "\n",
    "    map_filt = mapping.loc[mapping['empo_3'] == \"Water (non-saline)\"]\n",
    "    print(\"After selecting for biome, mapping has shape \" + str(map_filt.shape))\n",
    "\n",
    "    bools = [i in otu.columns.values for i in map_filt.index.values]\n",
    "    map_filt = map_filt.loc[bools]\n",
    "    print(\"After selecting just the samples present in the otu table: \" + str(map_filt.shape))\n",
    "\n",
    "    otu_sort = otu.reindex(sorted(otu.columns.values), axis = 1)\n",
    "    map_filt_sort = map_filt.reindex(sorted(map_filt.index.values), axis = 0)\n",
    "    nsamples = map_filt.shape[0]\n",
    "    bools_correct = [map_filt_sort.index.values[i] == otu_sort.columns.values[i] for i in range(nsamples)]\n",
    "    print(\"After rearranging, we have \" + str(np.sum(bools_correct)) + \" matching samples\")\n",
    "    if (np.sum(bools_correct) == map_filt_sort.shape[0]) and (np.sum(bools_correct) == otu_sort.shape[1]):\n",
    "        print(\"Safe to continue\")\n",
    "    else:\n",
    "        print(\"STOP! Something is wrong.\")\n",
    "        \n",
    "        \n",
    "    #temperature\n",
    "    #phosphate\n",
    "    #ammonia\n",
    "    #map_filt_sort.loc[map_filt_sort['temperature_deg_c']]\n",
    "    bools =  ~map_filt_sort['temperature_deg_c'].isnull() \n",
    "    map_temp = map_filt_sort.loc[~map_filt_sort['temperature_deg_c'].isnull()]\n",
    "    otu_temp = otu_sort.loc[:, bools]\n",
    "    bools_correct = [map_temp.index.values[i] == otu_temp.columns.values[i] for i in range(map_temp.shape[0])]\n",
    "    print(\"We will be working with \" + str(np.sum(bools_correct)) + \" samples that have temperature information\")\n",
    "    \n",
    "    \n",
    "    #One final check after all transformations\n",
    "    qual_vecs = qual_vecs_sort\n",
    "    bools_correct = [qual_vecs.index.values[i] == otu_temp.index.values[i] for i in range(ntaxa)]\n",
    "    if (np.sum(bools_correct) == qual_vecs_sort.shape[0]) and (np.sum(bools_correct) == otu.shape[0]):\n",
    "        print(\"Safe to continue\")\n",
    "    else:\n",
    "        print(\"STOP! Something is wrong.\")\n",
    "        \n",
    "    pd_qual_vecs = pd.DataFrame(qual_vecs)\n",
    "    otu = otu_temp.T\n",
    "    \n",
    "    otu_train = otu.loc[map_temp.study_id != 1883, :]\n",
    "    otu_test = otu.loc[map_temp.study_id == 1883, :]\n",
    "    map_train = map_temp.loc[map_temp.study_id != 1883, :]\n",
    "    map_test = map_temp.loc[map_temp.study_id == 1883, :]\n",
    "    #map_temp = map_temp.loc[map_temp.study_id != 1041, :]\n",
    "    return(otu_train, otu_test, pd_qual_vecs, map_train, map_temp)\n",
    "\n",
    "\n",
    "def normalize(otu):\n",
    "    #Normalize\n",
    "    sample_sums = otu.sum(axis=1)\n",
    "    otu_norm = otu.div(sample_sums, axis=0)\n",
    "    return(otu_norm)\n",
    "\n",
    "def biofilter(otu):\n",
    "    #Filter for useful taxa\n",
    "    file = open('feature_selection/taxa_lowphy_highcos.obj', 'rb')\n",
    "    taxa_lowphy_highcos = pickle.load(file)\n",
    "    file.close()\n",
    "    otu_use = otu[list(taxa_lowphy_highcos)]\n",
    "    return(otu_use)\n",
    "\n",
    "def embed(otu, qual_vecs):\n",
    "    qual_vecs_use = qual_vecs.loc[list(otu.columns.values)]\n",
    "    df = pd.DataFrame(np.dot(otu, qual_vecs_use), index = otu.index.values)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "otu_train, otu_test, qual_vecs_500, map_train, map_test = getData(qual_vec_type = \"500\")\n",
    "\n",
    "otu_norm = normalize(otu_train)\n",
    "otu_biofilter_norm = biofilter(otu_norm) #Biofilter using new embeddings\n",
    "otu_emb_norm_500 = embed(otu_norm, qual_vecs_500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 3)\n",
    "mses = list()\n",
    "features_list = list()\n",
    "for train_i, test_i in kf.split(otu_norm):\n",
    "    X_train, X_test = otu_norm.iloc[train_i,:], otu_norm.iloc[test_i, :]\n",
    "    y_train, y_test = map_train.iloc[train_i, :], map_train.iloc[test_i, :]\n",
    "    y_train = y_train.temperature_deg_c\n",
    "    y_test = y_test.temperature_deg_c\n",
    "    \n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    k_obj = SelectKBest(mutual_info_regression, k= 10).fit(X_train, y_train)\n",
    "    features = otu_norm.columns.values[k_obj.get_support()]\n",
    "    \n",
    "    \n",
    "    print(\"features selected\")\n",
    "    m = svm.SVR(gamma = \"scale\")\n",
    "    m.fit(X_train[features], y_train)\n",
    "    print(\"Model fit\")\n",
    "    \n",
    "    preds = m.predict(X_test[features])\n",
    "    mse = np.mean([np.square(y_test[i] - preds[i]) for i in range(len(preds))])\n",
    "    mses.append(mse)\n",
    "    features_list.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = set(features_list[0])\n",
    "for i in range(1, len(features_list)):\n",
    "    intersection = intersection.intersection(set(features_list[i]))\n",
    "    \n",
    "intersection\n",
    "file = open(\"feature_selection/ml_filtered_features.obj\", \"wb\")\n",
    "pickle.dump(intersection, file)\n",
    "file.close()\n",
    "\n",
    "file = open(\"feature_selection/ml_filtered_cv_mses.obj\", \"wb\")\n",
    "pickle.dump(mses, file)\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
