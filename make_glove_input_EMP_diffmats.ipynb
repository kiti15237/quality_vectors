{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pandas import DataFrame as df\n",
    "import numpy as np\n",
    "import csv\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "otu_animal_sur = pd.read_csv('data/silva/split/Animal_surface.txt', sep = '\\t', index_col = 0)\n",
    "otu_plant_corpus = pd.read_csv('data/silva/split/Plant_corpus.txt', sep = '\\t', index_col = 0)\n",
    "otu_sediment_nonsaline = pd.read_csv('data/silva/split/Sediment_(non-saline).txt', sep = '\\t', index_col = 0)\n",
    "otu_water_saline = pd.read_csv('data/silva/split/Water_(saline).txt', sep = '\\t', index_col = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "otu_plant_surface = pd.read_csv('data/silva/split/Plant_surface.txt', sep = '\\t', index_col = 0)\n",
    "otu_sediment_saline = pd.read_csv('data/silva/split/Sediment_(saline).txt', sep = '\\t', index_col = 0)\n",
    "otu_surface_nonsaline = pd.read_csv('data/silva/split/Surface_(non-saline).txt', sep = '\\t', index_col = 0)\n",
    "otu_soil_nonsaline = pd.read_csv('data/silva/split/Soil_(non-saline).txt', sep = '\\t', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = ['animal_dg'] * otu_animal_sur.shape[1] #number of samples\n",
    "y = y + ['plant_corpus'] * otu_plant_corpus.shape[1]\n",
    "y = y + ['sed_nosalt'] * otu_sediment_nonsaline.shape[1]\n",
    "y = y + ['water_salt'] * otu_water_saline.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.048033758304902134\n",
      "0.009912919656060025\n",
      "0.011569979056101182\n",
      "0.014144743295470151\n",
      "0.04105058831987347\n",
      "0.01013953488372093\n",
      "0.021521701701388344\n",
      "0.0547954932777883\n",
      "5216\n"
     ]
    }
   ],
   "source": [
    "def ratio(shape):\n",
    "    return(shape[1]/ shape[0])\n",
    "\n",
    "print(ratio(otu_animal_sur.shape))\n",
    "print(ratio(otu_plant_corpus.shape))\n",
    "print(ratio(otu_sediment_nonsaline.shape))\n",
    "print(ratio(otu_water_saline.shape))\n",
    "\n",
    "print(ratio(otu_plant_surface.shape))\n",
    "print(ratio(otu_sediment_saline.shape))\n",
    "print(ratio(otu_surface_nonsaline.shape))\n",
    "print(ratio(otu_soil_nonsaline.shape))\n",
    "print(len(y))\n",
    "\n",
    "#otu_animal_sur\n",
    "#plant_surface\n",
    "#soil_nonsaline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Throw samples with less than 5000 reads\n",
    "sample_sums = np.sum(otu, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35511, 15475)\n"
     ]
    }
   ],
   "source": [
    "otu_filter = otu.loc[:, sample_sums > 5000]\n",
    "print(otu_filter.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35275, 15475)\n"
     ]
    }
   ],
   "source": [
    "taxa_sums = np.sum(otu_filter, axis = 1)\n",
    "otu_filter = otu_filter.loc[taxa_sums > 0, :]\n",
    "print(otu_filter.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only useful for reducing data size when using already subsetted data. If using whole dataset, all taxa are present at least once\n",
    "#total_taxa_abund = otu.sum(axis = 1) #Should be ntaxa (5000) of them\n",
    "#otu_prune = otu.loc[total_taxa_abund > 0, :]\n",
    "#print(\"After deleting taxa that never appear, we have \" + str(otu_prune.shape[0]) + \" taxa in \" + str(otu_prune.shape[1]) + \" samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only keep taxa present in greater than 3.095 samples\n",
      "We will keep 21979 taxa\n"
     ]
    }
   ],
   "source": [
    "thresh = 0.0002 * otu_filter.shape[1] # at least 1 % of samples (10 in this case)\n",
    "print(\"Only keep taxa present in greater than \" + str(thresh) + \" samples\")\n",
    "binary = otu_filter > 0\n",
    "keep = binary.sum(axis = 1) >= thresh# Should be ntaxa\n",
    "binary = binary.loc[keep, :]\n",
    "print(\"We will keep \" + str(keep.sum()) +\" taxa\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35275\n",
      "(21979, 15475)\n"
     ]
    }
   ],
   "source": [
    "print(len(keep))\n",
    "print(binary.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split out a test set\n",
    "\n",
    "np.random.seed(15)\n",
    "test_samples = np.random.choice(binary.columns.values, 1500)\n",
    "f = open(\"data/AG_new/AG_test_samples.obj\", \"wb\")\n",
    "pickle.dump(test_samples, f)\n",
    "f.close()\n",
    "\n",
    "binary_train = binary.loc[:, [not(i in test_samples) for i in binary.columns.values ]]\n",
    "otu_train = otu_filter.loc[:, [not(i in test_samples) for i in binary.columns.values ]]\n",
    "otu_test = otu_filter[test_samples]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35275, 14027)\n",
      "(35275, 1500)\n",
      "(35275, 15475)\n"
     ]
    }
   ],
   "source": [
    "#Test text output with small file\n",
    "#otu_filter[\"#OTU ID\"].head()\n",
    "#tmp = otu_filter.head()\n",
    "#tmp = tmp.iloc[:, [0,1,2,3,4]]\n",
    "#tmp.head()\n",
    "#tmp.to_csv(\"silva/test_out.csv\", sep = \"\\t\", index = False)\n",
    "print(otu_train.shape)\n",
    "print(otu_test.shape)\n",
    "print(otu_filter.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "otu_train_filter = otu_train.loc[np.array(keep), :]\n",
    "otu_test_filter = otu_test.loc[np.array(keep), :]\n",
    "otu_filter = otu_filter.loc[keep, :]\n",
    "\n",
    "otu_filter.to_csv(\"data/AG_new/otu_filtered_AG_02perc.csv\", sep = \"\\t\", index = True)\n",
    "otu_train_filter.to_csv(\"data/AG_new/otu_filtered_train_AG_02perc.csv\", sep = \"\\t\", index = True)\n",
    "otu_test_filter.to_csv(\"data/AG_new/otu_filtered_test_AG_02perc.csv\", sep = \"\\t\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21979, 15475)\n"
     ]
    }
   ],
   "source": [
    "print(otu_filter.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_text = []\n",
    "for i in range(binary_train.shape[1]):\n",
    "    taxa_share = binary_train.index[binary_train.iloc[:,i] == True]\n",
    "    file_text.append(taxa_share)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of taxa in any given sample is: 3590\n",
      "Found at 43\n"
     ]
    }
   ],
   "source": [
    "lengths = []\n",
    "for taxa_list in file_text:\n",
    "    lengths.append(len(taxa_list))\n",
    "max_val = max(lengths)\n",
    "max_ind = np.argmax(lengths)\n",
    "print(\"Max number of taxa in any given sample is: \" + str(max_val))\n",
    "print(\"Found at \" + str(max_ind))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write Glove input file\n",
    "with open('data/AG_new/glove_input_AG_02perc.txt', mode = 'w', newline='') as file:\n",
    "    writer = csv.writer(file, delimiter = \"\\t\", quoting = csv.QUOTE_NONE, escapechar = '')\n",
    "    for taxa_list in file_text:\n",
    "        writer.writerow(taxa_list)\n",
    "file.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
